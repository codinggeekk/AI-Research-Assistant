{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ea1b4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- FINAL RESEARCH REPORT ---\n",
      "\n",
      "Introduction:\n",
      "This report summarizes information about physics using only Wikipedia content.\n",
      "\n",
      "Findings:\n",
      "- Who is physics?: (Wikipedia) Physics is the scientific study of matter, its fundamental constituents, its motion and behavior through space and time, and the related entities of energy and force. It is one of the most fundamental scientific disciplines. A scientist who specializes in the field of physics is called a physicist.\n",
      "\n",
      "- What are the most important facts about physics?: (Wikipedia) Physics is the scientific study of matter, its fundamental constituents, its motion and behavior through space and time, and the related entities of energy and force. It is one of the most fundamental scientific disciplines. A scientist who specializes in the field of physics is called a physicist.\n",
      "\n",
      "- What are recent developments related to physics?: (Wikipedia) The Solvay Conferences have been devoted to preeminent unsolved problems in both physics and chemistry. They began with the historic invitation-only 1911 Solvay Conference on Physics, considered a turning point in the world of physics, and are ongoing.\n",
      "\n",
      "Conclusion:\n",
      "This concludes the synthesized summary based solely on Wikipedia extracts.\n",
      "\n",
      "\n",
      "--- END OF REPORT ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "main_wikipedia_only.py\n",
    "\n",
    "Multi-agent research assistant that uses ONLY Wikipedia (no ML models, no external APIs).\n",
    "- Planner: simple templated questions derived from the topic.\n",
    "- Search: Wikipedia REST summary endpoint + search fallback.\n",
    "- Synthesizer: combine the Wikipedia extracts into a final report.\n",
    "\n",
    "Usage:\n",
    "    python main_wikipedia_only.py\n",
    "Then enter a topic when prompted.\n",
    "\n",
    "Notes:\n",
    "- Requires 'requests' (pip install requests).\n",
    "- Prints only the final report (no extra debug output).\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "from typing import List, Tuple, Optional\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "USER_AGENT = \"WikiResearchAssistant/1.0 (contact: none)\"\n",
    "\n",
    "WIKIPEDIA_SUMMARY_URL = \"https://en.wikipedia.org/api/rest_v1/page/summary/{}\"\n",
    "WIKIPEDIA_SEARCH_URL = \"https://en.wikipedia.org/w/api.php?action=query&list=search&srsearch={}&format=json&utf8=1\"\n",
    "\n",
    "# -------------------------\n",
    "# Utilities: sanitize topic / question -> query\n",
    "# -------------------------\n",
    "def sanitize_topic(raw: str) -> str:\n",
    "    if not raw:\n",
    "        return \"\"\n",
    "    s = raw.strip()\n",
    "    s = re.sub(r'^(who is|who was|what is|what are|tell me about|give me info on|info about)\\s+', '', s, flags=re.I).strip()\n",
    "    return s\n",
    "\n",
    "def extract_query_from_question(question: str) -> str:\n",
    "    q = question.strip()\n",
    "    q = re.sub(r'^(who is|who was|what is|what are|tell me about|give me details on|provide info on)\\s+', '', q, flags=re.I).strip()\n",
    "    q = q.rstrip(\" ?.\")\n",
    "    return q\n",
    "\n",
    "# -------------------------\n",
    "# Wikipedia helpers\n",
    "# -------------------------\n",
    "def wikipedia_summary(title_or_query: str, timeout: int = 10) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Try the Wikipedia REST summary for title_or_query (replace spaces with underscores).\n",
    "    If not found (404 or missing extract), return None.\n",
    "    \"\"\"\n",
    "    if not title_or_query:\n",
    "        return None\n",
    "    headers = {\"User-Agent\": USER_AGENT}\n",
    "    # try direct title (underscore)\n",
    "    for candidate in (title_or_query.replace(\" \", \"_\"), title_or_query):\n",
    "        url = WIKIPEDIA_SUMMARY_URL.format(quote_plus(candidate))\n",
    "        try:\n",
    "            r = requests.get(url, headers=headers, timeout=timeout)\n",
    "            if r.status_code == 200:\n",
    "                j = r.json()\n",
    "                # 'extract' is human readable summary\n",
    "                extract = j.get(\"extract\")\n",
    "                if extract:\n",
    "                    return extract.strip()\n",
    "                # sometimes description exists\n",
    "                if j.get(\"description\"):\n",
    "                    return j.get(\"description\").strip()\n",
    "            # if 404 or no useful info, continue to search fallback\n",
    "        except requests.RequestException:\n",
    "            # network or timeout -> treat as no result\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def wikipedia_search_then_summary(query: str, timeout: int = 10) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Use Wikipedia search API to find most relevant page title, then get its summary.\n",
    "    \"\"\"\n",
    "    if not query:\n",
    "        return None\n",
    "    headers = {\"User-Agent\": USER_AGENT}\n",
    "    url = WIKIPEDIA_SEARCH_URL.format(quote_plus(query))\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers, timeout=timeout)\n",
    "        if r.status_code != 200:\n",
    "            return None\n",
    "        j = r.json()\n",
    "        hits = j.get(\"query\", {}).get(\"search\", [])\n",
    "        if not hits:\n",
    "            return None\n",
    "        first = hits[0]\n",
    "        title = first.get(\"title\")\n",
    "        if not title:\n",
    "            return None\n",
    "        # fetch summary for that title\n",
    "        return wikipedia_summary(title, timeout=timeout)\n",
    "    except requests.RequestException:\n",
    "        return None\n",
    "\n",
    "# -------------------------\n",
    "# Agents (Wikipedia-only)\n",
    "# -------------------------\n",
    "def planner_agent(topic: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Simple deterministic planner: produce 3 templated research questions based on topic.\n",
    "    \"\"\"\n",
    "    t = sanitize_topic(topic)\n",
    "    if not t:\n",
    "        return []\n",
    "    questions = [\n",
    "        f\"Who is {t}?\",\n",
    "        f\"What are the most important facts about {t}?\",\n",
    "        f\"What are recent developments related to {t}?\"\n",
    "    ]\n",
    "    return questions\n",
    "\n",
    "def search_agent(question: str) -> str:\n",
    "    \"\"\"\n",
    "    For a given question, attempt to fetch a concise factual answer using Wikipedia.\n",
    "    Returns the raw Wikipedia extract (or a short message if not found).\n",
    "    \"\"\"\n",
    "    query = extract_query_from_question(question)\n",
    "    if not query:\n",
    "        return \"(No query generated from question.)\"\n",
    "\n",
    "    # Try direct summary by title/title-variant\n",
    "    summary = wikipedia_summary(query)\n",
    "    if summary:\n",
    "        return f\"(Wikipedia) {summary}\"\n",
    "\n",
    "    # If not found, try search fallback\n",
    "    summary2 = wikipedia_search_then_summary(query)\n",
    "    if summary2:\n",
    "        return f\"(Wikipedia) {summary2}\"\n",
    "\n",
    "    return \"(Wikipedia) No article found for the query.\"\n",
    "\n",
    "def synthesizer_agent(topic: str, research_results: List[Tuple[str, str]]) -> str:\n",
    "    \"\"\"\n",
    "    Combine results into a simple report. Use only the gathered Wikipedia text.\n",
    "    \"\"\"\n",
    "    topic_clean = sanitize_topic(topic)\n",
    "    intro = f\"Introduction:\\nThis report summarizes information about {topic_clean} using only Wikipedia content.\\n\\n\"\n",
    "\n",
    "    findings = \"Findings:\\n\"\n",
    "    for q, data in research_results:\n",
    "        # Keep each finding concise: use first 800 characters of the wiki text for safety\n",
    "        snippet = data.strip()\n",
    "        if len(snippet) > 800:\n",
    "            snippet = snippet[:800].rsplit(\".\", 1)[0] + \"...\"\n",
    "        findings += f\"- {q}: {snippet}\\n\\n\"\n",
    "\n",
    "    conclusion = \"Conclusion:\\nThis concludes the synthesized summary based solely on Wikipedia extracts.\\n\"\n",
    "    return intro + findings + conclusion\n",
    "\n",
    "# -------------------------\n",
    "# Conductor / main (CLI)\n",
    "# -------------------------\n",
    "def main():\n",
    "    try:\n",
    "        topic = input(\"What topic would you like me to research today? \").strip()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nInterrupted. Exiting.\")\n",
    "        return\n",
    "\n",
    "    if not topic:\n",
    "        print(\"A topic is required. Exiting.\")\n",
    "        return\n",
    "\n",
    "    questions = planner_agent(topic)\n",
    "    research_results = []\n",
    "    for q in questions:\n",
    "        ans = search_agent(q)\n",
    "        research_results.append((q, ans))\n",
    "        # be polite to Wikipedia\n",
    "        time.sleep(0.3)\n",
    "\n",
    "    final_report = synthesizer_agent(topic, research_results)\n",
    "\n",
    "    # Print ONLY the final report\n",
    "    print(\"\\n\\n--- FINAL RESEARCH REPORT ---\\n\")\n",
    "    print(final_report)\n",
    "    print(\"\\n--- END OF REPORT ---\\n\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
